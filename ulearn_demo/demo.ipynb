{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717c4b19-7aed-4906-814e-ecdb6dea11ad",
   "metadata": {},
   "source": [
    "# UnionML Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e115d12-3abf-47a0-834e-5e423010f1b3",
   "metadata": {},
   "source": [
    "Here we use the UnionML library to simplify training a pytorch neural network model for quickdraw.\n",
    "\n",
    "A unionml app is composed of two objects: Dataset and Model. Together, they expose method decorator entrypoints that serve as the core building blocks of an end-to-end machine learning application. Here we implement the train entrypoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5eedd9-10b0-48de-9d75-294dca73d406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing quickdraw_classifier.train, execution name: fed4d7985216a4f0ead7.\n",
      "Go to https://playground.hosted.unionai.cloud/console/projects/unionml/domains/development/executions/fed4d7985216a4f0ead7 to see the execution in the console.\n"
     ]
    }
   ],
   "source": [
    "from pictionary_app import model\n",
    "\n",
    "num_classes = 200\n",
    "\n",
    "execution = model.remote_train(\n",
    "    hyperparameters={\"num_classes\": num_classes},\n",
    "    trainer_kwargs={\"num_epochs\": 1},\n",
    "    data_dir=\"./data\",\n",
    "    max_examples_per_class=10000,\n",
    "    class_limit=num_classes,\n",
    "    app_version='71ea176253225b67d5f9e3e2a59354913ffd85f0',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432e54e-e28c-4435-978a-70146c33e021",
   "metadata": {},
   "source": [
    "Now, wait for the execution to complete and then load model from the remote training job. We can easily interact with the fetched model locally to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e99bf3-9d6a-464b-8189-43bfc4a55b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.remote_load(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef3f18-ae57-4d13-b99f-ebedc98393cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(\n",
    "    fn=model.predict,\n",
    "    inputs=\"sketchpad\",\n",
    "    outputs=\"label\",\n",
    "    live=True,\n",
    "    allow_flagging=\"never\",\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de868d82-2c31-4c2b-92ca-1984214fdd7c",
   "metadata": {},
   "source": [
    "# Flytekit Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21320282-1153-4578-8109-4dc1b7426910",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Workflow for Batch Prediction\n",
    "UnionML is backed by flytekit, a general purpose SDK for expressing Flyte workflows. In this section, we define a workflow that uses the model we trained above, and run batch prediction on a larger dataset on the same Flyte backend.\n",
    "\n",
    "## Workflow overview\n",
    "This workflow \n",
    "1. Downloads the available quickdraw categories: `download_quickdraw_dataset`\n",
    "2. Downloads the quickdraw labeled dataset: `download_quickdraw_dataset`\n",
    "3. Attempts to label and generate features for randomly selected drawings in the dataset: `generate_input`\n",
    "4. Tags the labeled drawings with the model with their computed features:`prepare_map_inputs`\n",
    "5. Generates a prediction for each drawing: `batch_predictions_task`\n",
    "6. Finally return the prediction along with their corresponding computed features and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a2b1fe-ceff-4578-a548-9569a3e84d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "from typing import List\n",
    "from flytekit import workflow\n",
    "\n",
    "from flytekit_demo.batch_predictions import batch_predictions_task, prepare_map_inputs, download_quickdraw_dataset, generate_input, download_quickdraw_class_names\n",
    "\n",
    "@workflow\n",
    "def batch_predict(\n",
    "    model_object: torch.nn.Module,\n",
    "    n_entries: int,\n",
    "    max_items_per_class: int = 1000,\n",
    "    num_classes: int = 200,\n",
    ") -> (List[dict], List[torch.Tensor], List[str]):\n",
    "    class_names = download_quickdraw_class_names()\n",
    "    dataset = download_quickdraw_dataset(max_items_per_class=max_items_per_class, num_classes=num_classes)\n",
    "    feature_list, label_list = generate_input(n_entries=n_entries, dataset=dataset, class_names=class_names)\n",
    "    map_input = prepare_map_inputs(model_object=model_object, feature_list=feature_list)\n",
    "    predictions = batch_predictions_task(input=map_input)\n",
    "    return predictions, feature_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727cd72a-9fac-4430-a282-f77a8034f20f",
   "metadata": {},
   "source": [
    "## Workflow Registration\n",
    "The workflow above still only exists locally in Python memory.  To tell Flyte about it, we create a `FlyteRemote` client object and register the workflow with the associated backend. The workflow is run in a prebuilt container with requisite dependencies. Once registered on Flyte, the workflow is immutable and versioned and can be used to generate reproducable output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606ab6a6-c767-4ffe-8911-777ec346bfd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from flytekit.remote import FlyteRemote\n",
    "from flytekit.configuration import Config, SerializationSettings, ImageConfig\n",
    "\n",
    "remote = FlyteRemote(config=Config.auto(config_file=\"./config/config-remote.yaml\"), \n",
    "                     data_upload_location=\"s3://open-compute-playground/data\",\n",
    "                     default_project=\"unionml\",\n",
    "                     default_domain=\"development\")\n",
    "image_config = ImageConfig.auto(img_name=\"ghcr.io/unionai-oss/unionml:quickdraw-classifier-71ea176253225b67d5f9e3e2a59354913ffd85f0\")\n",
    "wf = remote.register_workflow(batch_predict, \n",
    "                         version=\"71ea176253225b67d5f9e3e2a59354913ffd85f0\", \n",
    "                         serialization_settings=SerializationSettings(image_config=image_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2dbbb3-c6cf-4afd-9633-112cb0fd31e2",
   "metadata": {},
   "source": [
    "The remote client allows us to programmatically run the newly registered workflow on the hosted Flyte platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa0cec-a7d3-42d1-a131-2ad5e68a6430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = remote.execute(\n",
    "    wf,\n",
    "    inputs={\"model_object\": model.artifact.model_object, \"n_entries\": 20, \"max_items_per_class\": 1000, \"num_classes\": 200},\n",
    "    project=\"unionml\",\n",
    "    domain=\"development\",\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde72e8-72cd-49be-9cf3-67955b9d4ca5",
   "metadata": {},
   "source": [
    "Once the execution completes, we can fetch the typed outputs from the workflow run. In this case, the workflow outputs a series of predictions on the batch input. Let's go through and see how well the model performed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ddb44-5008-4eea-97ab-d3cee73a1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "predictions = execution.outputs.get('o0')\n",
    "feature_list = execution.outputs.get('o1')\n",
    "label_list = execution.outputs.get('o2')\n",
    "\n",
    "# Arrange results in a square where each image contains the prediction alongside with the original label\n",
    "fig = plt.figure(figsize=(40, 40))\n",
    "\n",
    "sqr = math.sqrt(len(predictions))\n",
    "rows = math.ceil(sqr)\n",
    "columns = math.floor(sqr) + 1\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    best_prediction = max(predictions[i], key=predictions[i].get)\n",
    "    expected_label = label_list[i]\n",
    "\n",
    "    fig.add_subplot(rows, columns, i + 1)\n",
    "    plt.imshow(feature_list[i], interpolation='bicubic')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"predicted: {best_prediction}\\nexpected: {expected_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}