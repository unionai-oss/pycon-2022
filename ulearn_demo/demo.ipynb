{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717c4b19-7aed-4906-814e-ecdb6dea11ad",
   "metadata": {},
   "source": [
    "# Challenge: Lets train a QuickDraw model & Deploy it as an online service\n",
    "In the following App we will create a [QuickDraw](https://quickdraw.withgoogle.com/) predictor App. The Dataset is available from [GCS](https://quickdraw.withgoogle.com/data) and contains more than **50 million** labeled drawings. Deep-Learning is a fantastic modeling technique to apply to a visual dataset like this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e115d12-3abf-47a0-834e-5e423010f1b3",
   "metadata": {},
   "source": [
    "## Build a UnionML app\n",
    "To train a QuickDraw model - we will use the UnionML. This is implemented in [main.py](pictionary_app/main.py) <-- **Click Here**\n",
    "\n",
    "## Now that the App is written, we can import and execute it in this interactive notebook\n",
    "\n",
    "Note we will simply train for 2 classes. this is because the model is a deep learning model and training for the large dataset may take too long locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244ac238-e4a4-4568-8d3b-ed40b166ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pictionary_app import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1107a10e-8864-405d-828e-449c1c2947c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "model.train(\n",
    "    hyperparameters={\"num_classes\": num_classes},\n",
    "    trainer_kwargs={\"num_epochs\": 1},\n",
    "    data_dir=\"./data\",\n",
    "    max_examples_per_class=10000,\n",
    "    class_limit=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1973c09a-3f49-486e-80cf-4fe3ef6ea1c1",
   "metadata": {},
   "source": [
    "### So local works, I want to train on larger dataset!\n",
    "Let us try to train the model on more data. But for this, we need a GPU. (For refernece training for 2 classes take almost 5 minutes on CPU and 5 seconds on GPU)\n",
    "but, how should we do that?\n",
    "\n",
    "this is where UnionML shines with the help of flyte in the backend. you can simply change the API from `train` to ``remote_train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5eedd9-10b0-48de-9d75-294dca73d406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing quickdraw_classifier.train, execution name: fd287d990d9854a8d940.\n",
      "Go to https://playground.hosted.unionai.cloud/console/projects/unionml/domains/development/executions/fd287d990d9854a8d940 to see the execution in the console.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 200\n",
    "num_epochs = 10\n",
    "\n",
    "execution = model.remote_train(\n",
    "    hyperparameters={\"num_classes\": num_classes},\n",
    "    trainer_kwargs={\"num_epochs\": num_epochs},\n",
    "    data_dir=\"./data\",\n",
    "    max_examples_per_class=10000,\n",
    "    class_limit=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432e54e-e28c-4435-978a-70146c33e021",
   "metadata": {},
   "source": [
    "Now, wait for the execution to complete and then load model from the remote training job. We can easily interact with the fetched model locally to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e99bf3-9d6a-464b-8189-43bfc4a55b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for execution fd287d990d9854a8d940 to complete...\n",
      "Done.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecution\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/go/src/github.com/unionai-oss/unionml/unionml/model.py:551\u001b[0m, in \u001b[0;36mModel.remote_load\u001b[0;34m(self, execution)\u001b[0m\n\u001b[1;32m    549\u001b[0m model_file \u001b[38;5;241m=\u001b[39m execution\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_object\u001b[39m\u001b[38;5;124m\"\u001b[39m, as_type\u001b[38;5;241m=\u001b[39mFlyteFile)\n\u001b[1;32m    550\u001b[0m model_file\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[0;32m--> 551\u001b[0m model_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact \u001b[38;5;241m=\u001b[39m ModelArtifact(\n\u001b[1;32m    553\u001b[0m     model_object,\n\u001b[1;32m    554\u001b[0m     execution\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    555\u001b[0m     execution\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    556\u001b[0m )\n",
      "File \u001b[0;32m~/src/go/src/github.com/unionai-oss/unionml/unionml/model.py:394\u001b[0m, in \u001b[0;36mModel.load\u001b[0;34m(self, file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/go/src/github.com/unionai-oss/unionml/unionml/model.py:602\u001b[0m, in \u001b[0;36mModel._default_loader\u001b[0;34m(self, file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(model_type, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 602\u001b[0m         deserialized_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    604\u001b[0m         deserialized_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(file, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/unionml-demo/lib/python3.9/site-packages/torch/serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m    712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/unionml-demo/lib/python3.9/site-packages/torch/serialization.py:920\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 920\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/unionml-demo/lib/python3.9/site-packages/torch/storage.py:181\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_bytes\u001b[39m(b):\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/unionml-demo/lib/python3.9/site-packages/torch/serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m    712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/unionml-demo/lib/python3.9/site-packages/torch/serialization.py:930\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    928\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    929\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m--> 930\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    934\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/unionml-demo/lib/python3.9/site-packages/torch/serialization.py:876\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    872\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_torch_load_uninitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m    875\u001b[0m     deserialized_objects[root_key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[0;32m--> 876\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    877\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    879\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m deserialized_objects[root_key]\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m view_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/unionml-demo/lib/python3.9/site-packages/torch/serialization.py:176\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 176\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.virtualenvs/unionml-demo/lib/python3.9/site-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m             storage_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda, \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/unionml-demo/lib/python3.9/site-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "model.remote_load(execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f9706-64c3-4786-842e-0004e5755dc7",
   "metadata": {},
   "source": [
    "### Alright, lets do a Live DEMO!\n",
    "Lets fetch the trained model ^^ and then using the wonderful library called [gradio](https://gradio.app/) to create an interactive widget to test out the model. \n",
    "\n",
    "**Note** UnionML makes it simple to create a webserver using the same ``predict`` method that you wrote as part of ``model``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef3f18-ae57-4d13-b99f-ebedc98393cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(\n",
    "    fn=model.predict,\n",
    "    inputs=\"sketchpad\",\n",
    "    outputs=\"label\",\n",
    "    live=True,\n",
    "    allow_flagging=\"never\",\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de868d82-2c31-4c2b-92ca-1984214fdd7c",
   "metadata": {},
   "source": [
    "# Challenge: Lets perform a batch prediction on a corpus of doodle drawings\n",
    "What if we want to run predictions on a large number of precreated doodles. Maybe you got them as a drop from somewhere and want to quickly get answers?\n",
    "\n",
    "The UnionML API is lacking. But, we know [Flyte](https://flyte.org/) should handle this. But, how can we reuse UnionML trained model from flytekit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21320282-1153-4578-8109-4dc1b7426910",
   "metadata": {
    "tags": []
   },
   "source": [
    "### UnionML is backed by Flytekit\n",
    "UnionML is backed by flytekit, a general purpose SDK for expressing Flyte workflows. In this section, we define a workflow that uses the model we trained above, and run batch prediction on a larger dataset on the same Flyte backend.\n",
    "\n",
    "\n",
    "### Let us construct a workflow\n",
    "** The workflow should look like so**\n",
    "1. Downloads the available quickdraw categories: `download_quickdraw_dataset`\n",
    "2. Downloads the quickdraw labeled dataset: `download_quickdraw_dataset`\n",
    "3. Attempts to label and generate features for randomly selected drawings in the dataset: `generate_input`\n",
    "4. Tags the labeled drawings with the model with their computed features:`prepare_map_inputs`\n",
    "5. Generates a prediction for each drawing: `batch_predictions_task`\n",
    "6. Finally return the prediction along with their corresponding computed features and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a2b1fe-ceff-4578-a548-9569a3e84d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "from typing import List\n",
    "from flytekit import workflow\n",
    "\n",
    "from flytekit_demo.batch_predictions import batch_predictions_task, prepare_map_inputs, download_quickdraw_dataset, generate_input, download_quickdraw_class_names\n",
    "\n",
    "@workflow\n",
    "def batch_predict(\n",
    "    model_object: torch.nn.Module,\n",
    "    n_entries: int,\n",
    "    max_items_per_class: int = 1000,\n",
    "    num_classes: int = 200,\n",
    ") -> (List[dict], List[torch.Tensor], List[str]):\n",
    "    class_names = download_quickdraw_class_names()\n",
    "    dataset = download_quickdraw_dataset(max_items_per_class=max_items_per_class, num_classes=num_classes)\n",
    "    feature_list, label_list = generate_input(n_entries=n_entries, dataset=dataset, class_names=class_names)\n",
    "    map_input = prepare_map_inputs(model_object=model_object, feature_list=feature_list)\n",
    "    predictions = batch_predictions_task(input=map_input)\n",
    "    return predictions, feature_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727cd72a-9fac-4430-a282-f77a8034f20f",
   "metadata": {},
   "source": [
    "### Ship the workflow to a Flyte cluster\n",
    "The workflow above still only exists locally in Python memory.  To tell Flyte about it, we create a `FlyteRemote` client object and register the workflow with the associated backend. The workflow is run in a prebuilt container with requisite dependencies. Once registered on Flyte, the workflow is immutable and versioned and can be used to generate reproducable output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "606ab6a6-c767-4ffe-8911-777ec346bfd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from flytekit.remote import FlyteRemote\n",
    "from flytekit.configuration import Config, SerializationSettings, ImageConfig\n",
    "\n",
    "remote = FlyteRemote(config=Config.auto(config_file=\"./config/config-remote.yaml\"), \n",
    "                     data_upload_location=\"s3://open-compute-playground/data\",\n",
    "                     default_project=\"unionml\",\n",
    "                     default_domain=\"development\")\n",
    "image_config = ImageConfig.auto(img_name=\"ghcr.io/unionai-oss/unionml:quickdraw-classifier-13853d05c77931543aa1b66dacc5e0a36dca5a17\")\n",
    "wf = remote.register_workflow(batch_predict, \n",
    "                         version=\"0.0.1\", \n",
    "                         serialization_settings=SerializationSettings(image_config=image_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2dbbb3-c6cf-4afd-9633-112cb0fd31e2",
   "metadata": {},
   "source": [
    "The remote client allows us to programmatically run the newly registered workflow on the hosted Flyte platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55fa0cec-a7d3-42d1-a131-2ad5e68a6430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'model_object'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m execution \u001b[38;5;241m=\u001b[39m remote\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m      2\u001b[0m     wf,\n\u001b[0;32m----> 3\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_object\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_object\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_entries\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_items_per_class\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m200\u001b[39m},\n\u001b[1;32m      4\u001b[0m     project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munionml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     domain\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevelopment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'model_object'"
     ]
    }
   ],
   "source": [
    "execution = remote.execute(\n",
    "    wf,\n",
    "    inputs={\"model_object\": model.artifact.model_object, \"n_entries\": 20, \"max_items_per_class\": 1000, \"num_classes\": 200},\n",
    "    project=\"unionml\",\n",
    "    domain=\"development\",\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde72e8-72cd-49be-9cf3-67955b9d4ca5",
   "metadata": {},
   "source": [
    "### \n",
    "\n",
    "Once the execution completes, we can fetch the typed outputs from the workflow run. In this case, the workflow outputs a series of predictions on the batch input. Let's go through and see how well the model performed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ddb44-5008-4eea-97ab-d3cee73a1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "predictions = execution.outputs.get('o0')\n",
    "feature_list = execution.outputs.get('o1')\n",
    "label_list = execution.outputs.get('o2')\n",
    "\n",
    "# Arrange results in a square where each image contains the prediction alongside with the original label\n",
    "fig = plt.figure(figsize=(40, 40))\n",
    "\n",
    "sqr = math.sqrt(len(predictions))\n",
    "rows = math.ceil(sqr)\n",
    "columns = math.floor(sqr) + 1\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    best_prediction = max(predictions[i], key=predictions[i].get)\n",
    "    expected_label = label_list[i]\n",
    "\n",
    "    fig.add_subplot(rows, columns, i + 1)\n",
    "    plt.imshow(feature_list[i], interpolation='bicubic')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"predicted: {best_prediction}\\nexpected: {expected_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
