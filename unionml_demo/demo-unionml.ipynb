{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717c4b19-7aed-4906-814e-ecdb6dea11ad",
   "metadata": {},
   "source": [
    "# Challenge: Lets train a QuickDraw model & Deploy it as an online service\n",
    "In the following App we will create a [QuickDraw](https://quickdraw.withgoogle.com/) predictor App. The Dataset is available from [GCS](https://quickdraw.withgoogle.com/data) and contains more than **50 million** labeled drawings. Deep-Learning is a fantastic modeling technique to apply to a visual dataset like this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e115d12-3abf-47a0-834e-5e423010f1b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build a UnionML app\n",
    "\n",
    "To train a QuickDraw model, we will use the UnionML, which is implemented in [main.py](pictionary_app/main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8606335d-0a4d-4f0a-9e35-cd0052eb7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a98f86d-50fe-4f2e-848e-1d9072535912",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export WANDB_API_KEY=\"bb3911fee5ec2805704ae7542fe46ecb69dd0a24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "244ac238-e4a4-4568-8d3b-ed40b166ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pictionary_app import model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273ded28-43f4-434b-9581-c97ecdb9af8a",
   "metadata": {},
   "source": [
    "## Train on a Small Dataset Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1107a10e-8864-405d-828e-449c1c2947c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Quickdraw Dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13531ede94fb48df93168cbceb1bae64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1000 examples for each class from the Quickdraw Dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56573fad05c74563b5de15abcc4f3cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 10000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mniels-bantilan\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nielsbantilan/git/unionml-demo/unionml_demo/wandb/run-20220614_111312-3u7qx9kx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/niels-bantilan/huggingface/runs/3u7qx9kx\" target=\"_blank\">quickdraw-med-2022-06-14-111312</a></strong> to <a href=\"https://wandb.ai/niels-bantilan/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./.tmp/outputs_20k_2022-06-14-111312/checkpoint-39\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./.tmp/outputs_20k_2022-06-14-111312\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  total_flos               =        0GF\n",
      "  train_loss               =     2.2989\n",
      "  train_runtime            = 0:00:28.88\n",
      "  train_samples_per_second =    346.202\n",
      "  train_steps_per_second   =       1.35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "   (1): ReLU()\n",
       "   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "   (4): ReLU()\n",
       "   (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "   (7): ReLU()\n",
       "   (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (9): Flatten(start_dim=1, end_dim=-1)\n",
       "   (10): Linear(in_features=2304, out_features=512, bias=True)\n",
       "   (11): ReLU()\n",
       "   (12): Linear(in_features=512, out_features=10, bias=True)\n",
       " ),\n",
       " {'train': 11.787109375})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "model.train(\n",
    "    hyperparameters={\"num_classes\": num_classes},\n",
    "    trainer_kwargs={\"num_epochs\": 1, \"batch_size\": 256},\n",
    "    data_dir=\"/tmp/quickdraw_data\",\n",
    "    max_examples_per_class=1000,\n",
    "    class_limit=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd79bbce-f0fe-47ec-b977-b16bd4f251f5",
   "metadata": {},
   "source": [
    "## Train on a Larger Dataset on a Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1973c09a-3f49-486e-80cf-4fe3ef6ea1c1",
   "metadata": {},
   "source": [
    "Let us try to train the model on more data. But for this, we need a GPU. (For refernece training for 2 classes take almost 5 minutes on CPU and 5 seconds on GPU)\n",
    "but, how should we do that?\n",
    "\n",
    "this is where UnionML shines with the help of flyte in the backend. you can simply change the API from `train` to ``remote_train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5eedd9-10b0-48de-9d75-294dca73d406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing quickdraw_classifier.train, execution name: f7599ac9a0231493eb5d.\n",
      "Go to https://playground.hosted.unionai.cloud/console/projects/unionml/domains/development/executions/f7599ac9a0231493eb5d to see the execution in the console.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 345\n",
    "max_examples_per_class = 20000\n",
    "num_epochs = 5\n",
    "batch_size = 2048\n",
    "\n",
    "execution = model.remote_train(\n",
    "    wait=False,\n",
    "    hyperparameters={\"num_classes\": num_classes},\n",
    "    trainer_kwargs={\"num_epochs\": num_epochs, \"batch_size\": batch_size},\n",
    "    data_dir=\"./data\",\n",
    "    max_examples_per_class=max_examples_per_class,\n",
    "    class_limit=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432e54e-e28c-4435-978a-70146c33e021",
   "metadata": {},
   "source": [
    "Now, wait for the execution to complete and then load model from the remote training job. We can easily interact with the fetched model locally to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e99bf3-9d6a-464b-8189-43bfc4a55b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for execution f7599ac9a0231493eb5d to complete...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "model.remote_load(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95c48476-6c6f-43db-a703-9a34191a8e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelArtifact(model_object=Sequential(\n",
       "  (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Flatten(start_dim=1, end_dim=-1)\n",
       "  (10): Linear(in_features=2304, out_features=512, bias=True)\n",
       "  (11): ReLU()\n",
       "  (12): Linear(in_features=512, out_features=345, bias=True)\n",
       "), hyperparameters=HyperparametersSchema(num_classes=345), metrics={'train': 76.10881042480469})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f9706-64c3-4786-842e-0004e5755dc7",
   "metadata": {},
   "source": [
    "### Create a Frontend Widget for our UnionML App\n",
    "\n",
    "Lets fetch the trained model ^^ and then using the wonderful library called [gradio](https://gradio.app/) to create an interactive widget to test out the model. \n",
    "\n",
    "**Note** UnionML makes it simple to create a webserver using the same ``predict`` method that you wrote as part of ``model``\n",
    "\n",
    "**Challenge** Draw a smiley face and see if the model understands it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e5fdee3-9f89-4bb5-967e-8497150fe341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hint: Set streaming=True for Sketchpad component to use live streaming.\n",
      "Running on local URL:  http://127.0.0.1:7860/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7fa5624de7c0>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None(<Task finishe...> result=None>)\n",
      "handle: <Handle>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nielsbantilan/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "TypeError: 'NoneType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(\n",
    "    fn=lambda img: img if img is None else model.predict(img),\n",
    "    inputs=\"sketchpad\",\n",
    "    outputs=\"label\",\n",
    "    live=True,\n",
    "    allow_flagging=\"never\",\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
